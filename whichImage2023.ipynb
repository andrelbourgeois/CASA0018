{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMl/1FvpmsELfzruOUbGWQT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andrelbourgeois/CASA0018/blob/main/whichImage2023.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6aE7ev35pcdp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 786
        },
        "outputId": "a8d9e4d7-ce3e-4abe-90f5-6af658d31491"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.9.2\n",
            "shape: (28, 28)\n",
            "label: 8\n",
            "Epoch 1/6\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4935 - accuracy: 0.8257\n",
            "Epoch 2/6\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3748 - accuracy: 0.8653\n",
            "Epoch 3/6\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3368 - accuracy: 0.8768\n",
            "Epoch 4/6\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3121 - accuracy: 0.8858\n",
            "Epoch 5/6\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2943 - accuracy: 0.8918\n",
            "Epoch 6/6\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2807 - accuracy: 0.8962\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.3680 - accuracy: 0.8688\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "0.00000029\n",
            "0.00000000\n",
            "0.00000004\n",
            "0.00000000\n",
            "0.00000002\n",
            "0.00286031\n",
            "0.00000069\n",
            "0.01619998\n",
            "0.00001928\n",
            "0.98091936\n",
            "9\n",
            "[2.8548911e-07 4.9422000e-10 4.4749019e-08 4.3561221e-10 1.8935140e-08\n",
            " 2.8603103e-03 6.8627406e-07 1.6199978e-02 1.9282757e-05 9.8091936e-01]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "#import tensorflow\n",
        "import tensorflow as tf\n",
        "\n",
        "#import a lib to help display an image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#print tf version\n",
        "print(tf.__version__)\n",
        "#create a variable that points to mnist fashion data using the tf.keras API\n",
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "#create two list and load a training and a testing list with mnist fashion data\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "#set a sample variable\n",
        "sample = 100;\n",
        "\n",
        "#print shape of sample variable from training images list\n",
        "print(\"shape:\", training_images[sample].shape)\n",
        "\n",
        "plt.imshow(training_images[sample], cmap=\"gray\")\n",
        "print(\"label:\", training_labels[sample])\n",
        "\n",
        "#to normalize the data the datasets can be divided over 255.0\n",
        "#this is because each pixel in the image can have a value between 0 and 255\n",
        "#this process generally speeds up learning and leads to faster convergence\n",
        "training_images = training_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "\n",
        "#building the model\n",
        "\n",
        "#to create the sequence of layers in the model we use \"Sequential\"\n",
        "#the first layer - Flatten - takes the 28x28 image and turns it into a 1D set\n",
        "#the first layer should be the same as your data\n",
        "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(input_shape=(28,28)),\n",
        "                                    #second - Dense - contains 128 neurons\n",
        "                                    # relu (rectified linear unit) - converts negative values to 0\n",
        "                                    # helps to keep us between 0 and 1\n",
        "                                    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "                                    #third - Dense - contains 10 neurons; one for each fashion category\n",
        "                                    #note the input to the model is a 28x28 image and the output is one of 10 neurons which relates to the 10 fashion categories.\n",
        "                                    #softmax - sets highest probability in neuron layer to 1 and rest to 0\n",
        "                                    #makes it easier to find most likely solution\n",
        "                                    #the number of neurons in the last layer\n",
        "                                    #should match the number of classes you are classifying for\n",
        "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "                                    ])\n",
        "\n",
        "#compile with an optimizer and a loss function\n",
        "model.compile(optimizer = tf.keras.optimizers.Adam(),\n",
        "              loss = \"sparse_categorical_crossentropy\",\n",
        "              metrics = [\"accuracy\"])\n",
        "\n",
        "#train model by calling model.fit (train with training data)\n",
        "model.fit(training_images, training_labels, epochs=6)\n",
        "\n",
        "#evaluate model by calling model.evaluate (evaluate with testing data)\n",
        "model.evaluate(test_images, test_labels)\n",
        "\n",
        "classifications = model.predict(test_images)\n",
        "\n",
        "for x in classifications[0]:\n",
        "  print(\"{:0.8f}\".format(x))\n",
        "\n",
        "  \n",
        "print(test_labels[0])\n",
        "print(classifications[0])\n"
      ]
    }
  ]
}